{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2f6395c",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; overflow: hidden;\">\n",
    "    <div style=\"width: 150px; float: left;\"> <img src=\"https://raw.githubusercontent.com/DataForScience/Networks/master/data/D4Sci_logo_ball.png\" alt=\"Data For Science, Inc\" align=\"left\" border=\"0\" width=150px> </div>\n",
    "    <div style=\"float: left; margin-left: 10px;\"> <h1>Generative AI with OpenAI API</h1>\n",
    "<h1>GPT Models</h1>\n",
    "        <p>Bruno Gon√ßalves<br/>\n",
    "        <a href=\"http://www.data4sci.com/\">www.data4sci.com</a><br/>\n",
    "            @bgoncalves, @data4sci</p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f57712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "import termcolor\n",
    "from termcolor import colored\n",
    "\n",
    "import os\n",
    "import gzip\n",
    "\n",
    "import tqdm as tq\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import watermark\n",
    "\n",
    "%load_ext watermark\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b834f9a",
   "metadata": {},
   "source": [
    "We start by printing out the versions of the libraries we're using for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "876a1b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.11.7\n",
      "IPython version      : 8.12.3\n",
      "\n",
      "Compiler    : Clang 14.0.6 \n",
      "OS          : Darwin\n",
      "Release     : 23.4.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 16\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: 00e27069c4e567040e2ae5b1b5259eb0a02807ab\n",
      "\n",
      "openai    : 1.20.0\n",
      "watermark : 2.4.3\n",
      "matplotlib: 3.8.0\n",
      "pandas    : 2.1.4\n",
      "json      : 2.0.9\n",
      "termcolor : 2.4.0\n",
      "tqdm      : 4.66.2\n",
      "numpy     : 1.26.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -n -v -m -g -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfbc9e5",
   "metadata": {},
   "source": [
    "Load default figure style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d7f3a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('d4sci.mplstyle')\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a32f69a",
   "metadata": {},
   "source": [
    "# Basic Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c9d274",
   "metadata": {},
   "source": [
    "The first step is generate API key on the OpenAI website and store it as the \"OPENAI_API_KEY\" variable in your local environment. Without it we won't be able to do anything. You can find your API key in your using settings: https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc1b830-97e3-443a-811c-ddd20d2ecbb9",
   "metadata": {},
   "source": [
    "Then we are ready to instantiate the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5f43171-b255-4219-a5dc-cc4535a47e89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OpenAI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'OpenAI' is not defined"
     ]
    }
   ],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60dc01d",
   "metadata": {},
   "source": [
    "We start by getting a list of supported models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e7643bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = json.loads(client.models.list().json())[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e14e3d",
   "metadata": {},
   "source": [
    "In total we have 33 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96f6b9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e11616",
   "metadata": {},
   "source": [
    "Along with some information about each model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "102a537d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'dall-e-3',\n",
       "  'created': 1698785189,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'system'},\n",
       " {'id': 'gpt-4-1106-preview',\n",
       "  'created': 1698957206,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'system'},\n",
       " {'id': 'whisper-1',\n",
       "  'created': 1677532384,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'openai-internal'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f448b4",
   "metadata": {},
   "source": [
    "But let's just get a list of model names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42962461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "babbage-002\n",
      "dall-e-2\n",
      "dall-e-3\n",
      "davinci-002\n",
      "gpt-3.5-turbo\n",
      "gpt-3.5-turbo-0125\n",
      "gpt-3.5-turbo-0301\n",
      "gpt-3.5-turbo-0613\n",
      "gpt-3.5-turbo-1106\n",
      "gpt-3.5-turbo-16k\n",
      "gpt-3.5-turbo-16k-0613\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-3.5-turbo-instruct-0914\n",
      "gpt-4\n",
      "gpt-4-0125-preview\n",
      "gpt-4-0613\n",
      "gpt-4-1106-preview\n",
      "gpt-4-1106-vision-preview\n",
      "gpt-4-turbo\n",
      "gpt-4-turbo-2024-04-09\n",
      "gpt-4-turbo-preview\n",
      "gpt-4-vision-preview\n",
      "gpt-4o\n",
      "gpt-4o-2024-05-13\n",
      "gpt-4o-test-shared\n",
      "text-embedding-3-large\n",
      "text-embedding-3-small\n",
      "text-embedding-ada-002\n",
      "tts-1\n",
      "tts-1-1106\n",
      "tts-1-hd\n",
      "tts-1-hd-1106\n",
      "whisper-1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(sorted([model[\"id\"] for model in model_list])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4770f275",
   "metadata": {},
   "source": [
    "## Basic Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ce70f1",
   "metadata": {},
   "source": [
    "The recommended model for exploration is `gpt-3.5-turbo`, so we'll stick with it for now. The basic setup is relatively straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adafc6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"What was Superman's weakness?\"\n",
    "        },\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa3d11a",
   "metadata": {},
   "source": [
    "Which produces a response object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44cbe6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.chat.chat_completion.ChatCompletion"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222b82bc",
   "metadata": {},
   "source": [
    "Which we can treat as a named tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad0fb2d",
   "metadata": {},
   "source": [
    "The model answer can be found in the \"message\" dictionary inside the \"choices\" list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "832a11d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Superman's weakness is the radioactive mineral known as kryptonite. When exposed to kryptonite, Superman loses his superhuman abilities and becomes vulnerable to harm.\", role='assistant', function_call=None, tool_calls=None))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f96500",
   "metadata": {},
   "source": [
    "To request multiple answers, we must include the `n` parameter with the number of answers we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "934d4574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.65 ms, sys: 2.16 ms, total: 9.81 ms\n",
      "Wall time: 5.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What are the different kinds of Kryptonite?\"},\n",
    "    ],\n",
    "    n=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c985ec",
   "metadata": {},
   "source": [
    "And we can access each of the answers individually int he choices list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bcad922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Assistant\n",
      "==========\n",
      "There are several different kinds of Kryptonite, each with its own specific effects on Superman:\n",
      "\n",
      "1. Green Kryptonite - The most common form of Kryptonite, it is deadly to Superman and weakens him both physically and mentally. Exposure to green Kryptonite can lead to nausea, weakness, and even death if left untreated.\n",
      "\n",
      "2. Red Kryptonite - Red Kryptonite has unpredictable effects on Superman, causing temporary changes in his powers and behavior. It can create temporary mutations, alter his personality, or even take away his powers entirely for a short period of time.\n",
      "\n",
      "3. Blue Kryptonite - Blue Kryptonite is harmless to Superman but affects Bizarro, a twisted version of Superman, in the same way that green Kryptonite affects the original Superman.\n",
      "\n",
      "4. Gold Kryptonite - Gold Kryptonite permanently removes Superman's powers, rendering him completely human and vulnerable to harm.\n",
      "\n",
      "5. White Kryptonite - White Kryptonite is deadly to plant life, specifically killing all plant-based life it comes in contact with.\n",
      "\n",
      "6. Black Kryptonite - Black Kryptonite can split a Kryptonian into two separate beings, one good and one evil. It is often used in storylines involving doppelgangers or alternate realities.\n",
      "\n",
      "These are just a few examples of the various types of Kryptonite that have been introduced in DC Comics over the years.\n",
      "==========\n",
      "\n",
      "==========\n",
      "Assistant\n",
      "==========\n",
      "There are several different types of Kryptonite in DC Comics, each with different effects on the superhero Superman. These include:\n",
      "\n",
      "1. Green Kryptonite: The most well-known and commonly used form of Kryptonite, green Kryptonite weakens Superman, robbing him of his powers and potentially killing him if exposed for too long.\n",
      "\n",
      "2. Red Kryptonite: Red Kryptonite has random and unpredictable effects on Superman, often causing temporary changes in his powers or personality.\n",
      "\n",
      "3. Blue Kryptonite: Blue Kryptonite affects Bizarro, a flawed clone of Superman, in the same way that green Kryptonite affects Superman.\n",
      "\n",
      "4. Gold Kryptonite: Gold Kryptonite permanently removes Superman's powers, making him permanently powerless.\n",
      "\n",
      "5. White Kryptonite: White Kryptonite is lethal to plant life, making it a threat to Kryptonian plant-based life forms.\n",
      "\n",
      "6. Black Kryptonite: Black Kryptonite has the ability to split a Kryptonian into two separate beings, each representing different aspects of their personality.\n",
      "\n",
      "7. Pink Kryptonite: Pink Kryptonite is jokingly said to turn Superman gay in a one-off gag in a comic book.\n",
      "\n",
      "8. Anti-Kryptonite: Anti-Kryptonite is harmful to Kryptonians, while being harmless to most other forms of life.\n",
      "==========\n",
      "\n",
      "==========\n",
      "Assistant\n",
      "==========\n",
      "There are multiple different types of Kryptonite that have been introduced in various comic book storylines over the years. Some of the most well-known varieties include:\n",
      "\n",
      "1. Green Kryptonite - The most common form of Kryptonite, green Kryptonite is deadly to Kryptonians like Superman and weakens them, sometimes leading to their death.\n",
      "\n",
      "2. Red Kryptonite - Red Kryptonite has unpredictable effects on Kryptonians, often causing temporary changes in their powers or personalities.\n",
      "\n",
      "3. Blue Kryptonite - Blue Kryptonite has been shown to have similar effects to green Kryptonite, but is specifically harmful to Bizarro, a flawed clone of Superman.\n",
      "\n",
      "4. Gold Kryptonite - Gold Kryptonite permanently removes a Kryptonian's powers, rendering them powerless.\n",
      "\n",
      "5. White Kryptonite - White Kryptonite is deadly to plant life, causing plants to wither and die upon exposure.\n",
      "\n",
      "6. Black Kryptonite - Black Kryptonite has the ability to split Kryptonians into two separate beings - one good and one evil.\n",
      "\n",
      "These are just a few examples of the different types of Kryptonite that have been introduced in DC Comics. There may be additional variations or new types introduced in future storylines.\n",
      "==========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for output in response.choices:\n",
    "    print(\"==========\")\n",
    "    print(output.message.role.title()) \n",
    "    print(\"==========\")\n",
    "    print(output.message.content)\n",
    "    print(\"==========\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "279d48c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=814, prompt_tokens=17, total_tokens=831)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18509d4",
   "metadata": {},
   "source": [
    "# Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ddb64d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 ms, sys: 2.92 ms, total: 11.9 ms\n",
      "Wall time: 5.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a short story\"},\n",
    "    ],\n",
    "    temperature=1.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22fd09b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a little girl named Lily who lived in a small town at the edge of a lush forest. Lily loved wandering through the woods, chasing butterflies, and listening to the birds chirping in the trees.\n",
      "\n",
      "One day, while out exploring, Lily stumbled upon a hidden glen filled with colorful flowers and sparkling stream. As she gazed in awe at the beauty around her, she noticed a small creature hiding behind a rock. It was a fairy, with shimmering wings and a mischievous twinkle in her eye.\n",
      "\n",
      "The fairy introduced herself as Luna, and told Lily that she was the guardian of the secret glen. She explained that the glen was a special place, full of magic and wonder, that only those with pure hearts could find.\n",
      "\n",
      "Lily and Luna spent the day together, dancing in meadows and flying through the trees. As the sun began to set, Luna revealed a secret spring hidden in a grove of silver birch trees. She told Lily that anyone who drank from the spring would be granted a wish.\n",
      "\n",
      "Lily closed her eyes and made her wish with all her heart, a wish for happiness and love for everyone in the world. When she opened her eyes, she saw that the whole forest was bathed in a warm, golden light, and she knew that her wish had come true. From that day on, the glen became a place of peace and joy for all who found it.\n",
      "\n",
      "And so, Lily and Luna remained friends, guardians of the secret glen and spread love and magic wherever they went. The end.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86beb86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.75 ms, sys: 2.51 ms, total: 12.3 ms\n",
      "Wall time: 4.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a short story\"},\n",
    "    ],\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1855d3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a small village nestled in the mountains, there lived a young girl named Lily. She was known for her kindness and generosity, always willing to help those in need.\n",
      "\n",
      "One day, a terrible storm hit the village, causing widespread damage and leaving many families homeless. Lily knew she had to do something to help. She gathered her friends and together they started a relief effort, collecting food, clothing, and supplies for those affected by the storm.\n",
      "\n",
      "As they worked tirelessly to distribute the donations, word of Lily's kindness spread throughout the village. Soon, people from neighboring towns came to help, and the relief effort grew into a full-fledged community project.\n",
      "\n",
      "Thanks to Lily's leadership and the support of the villagers, the affected families were able to rebuild their homes and their lives. The village came together in a way they never had before, united by a common goal of helping those in need.\n",
      "\n",
      "From that day on, Lily was known as a hero in the village, a shining example of the power of kindness and compassion. And though the storm had caused destruction, it had also brought the community closer together, showing them the strength they had when they worked together as one.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff6e2bc",
   "metadata": {},
   "source": [
    "# Function Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ec02e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(messages, functions):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        # Define the functions the model is allowed to use\n",
    "        functions=functions\n",
    "    )\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85bfb94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_conversation(messages):\n",
    "    role_to_color = {\n",
    "        \"system\": \"red\",\n",
    "        \"user\": \"green\",\n",
    "        \"assistant\": \"blue\",\n",
    "        \"function\": \"magenta\",\n",
    "    }\n",
    "    \n",
    "    for message in messages:\n",
    "        print(message)\n",
    "        if message[\"role\"] == \"system\":\n",
    "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message['role']]))\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message['role']]))\n",
    "        elif message[\"role\"] == \"assistant\" and message['function_call']:\n",
    "            print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color[message['role']]))\n",
    "        elif message[\"role\"] == \"assistant\" and not message['function_call']:\n",
    "            print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message['role']]))\n",
    "        elif message[\"role\"] == \"function\":\n",
    "            print(colored(f\"function ({message.name}): {message.content}\\n\", role_to_color[message.role]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44263a09",
   "metadata": {},
   "source": [
    "Let's create some function specifications to interface with a hypothetical weather API. We'll pass these function specification to the Chat Completions API in order to generate function arguments that adhere to the specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d50ae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"format\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"location\", \"format\"],\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fe13f7",
   "metadata": {},
   "source": [
    "If we prompt the model about the current weather, it will respond with some clarifying questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dea82333",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "messages.append(\n",
    "    {\"role\": \"system\", \n",
    "     \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"\n",
    "    })\n",
    "\n",
    "messages.append(\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": \"What's the weather like today\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "206a9a1c-0dc6-411f-b634-1a06572c4567",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_response = chat(messages, functions=functions)\n",
    "assistant_message = chat_response.choices[0].message\n",
    "messages.append({\n",
    " \"role\":  assistant_message.role,\n",
    " \"content\":  assistant_message.content,\n",
    " \"function_call\":  assistant_message.function_call,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ddfa4616-a4a2-435d-8c42-00417ddcf412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'system', 'content': \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"}\n",
      "\u001b[31msystem: Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\n",
      "\u001b[0m\n",
      "{'role': 'user', 'content': \"What's the weather like today\"}\n",
      "\u001b[32muser: What's the weather like today\n",
      "\u001b[0m\n",
      "{'role': 'assistant', 'content': 'Sure, could you please provide me with your current location or the city you would like to know the weather for?', 'function_call': None}\n",
      "\u001b[34massistant: Sure, could you please provide me with your current location or the city you would like to know the weather for?\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pretty_print_conversation(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa5dfb9",
   "metadata": {},
   "source": [
    "Once we provide the missing information, it will generate the appropriate function arguments for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82527ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": \"I'm in New York, NY.\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82f112a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_response = chat(messages, functions=functions)\n",
    "assistant_message = chat_response.choices[0].message\n",
    "messages.append({\n",
    " \"role\":  assistant_message.role,\n",
    " \"content\":  assistant_message.content,\n",
    " \"function_call\":  assistant_message.function_call,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85060c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'system', 'content': \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"}\n",
      "\u001b[31msystem: Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\n",
      "\u001b[0m\n",
      "{'role': 'user', 'content': \"What's the weather like today\"}\n",
      "\u001b[32muser: What's the weather like today\n",
      "\u001b[0m\n",
      "{'role': 'assistant', 'content': 'Sure, could you please provide me with your current location or the city you would like to know the weather for?', 'function_call': None}\n",
      "\u001b[34massistant: Sure, could you please provide me with your current location or the city you would like to know the weather for?\n",
      "\u001b[0m\n",
      "{'role': 'user', 'content': \"I'm in New York, NY.\"}\n",
      "\u001b[32muser: I'm in New York, NY.\n",
      "\u001b[0m\n",
      "{'role': 'assistant', 'content': None, 'function_call': FunctionCall(arguments='{\"location\":\"New York, NY\",\"format\":\"celsius\"}', name='get_current_weather')}\n",
      "\u001b[34massistant: FunctionCall(arguments='{\"location\":\"New York, NY\",\"format\":\"celsius\"}', name='get_current_weather')\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pretty_print_conversation(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8a12a1",
   "metadata": {},
   "source": [
    "## Few-shot prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bca0dde",
   "metadata": {},
   "source": [
    "We can also provide several examples of mappings between input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80a730c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This last-minute change means we can't spend excessive time on the client's project.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful, pattern-following assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Help me translate the following corporate jargon into plain English.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Sure, I'd be happy to!\"},\n",
    "        {\"role\": \"user\", \"content\": \"New synergies will help drive top-line growth.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Things working well together will increase revenue.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Let's circle back when we have more bandwidth to touch base on opportunities for increased leverage.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Let's talk later when we're less busy about how to do better.\"},\n",
    "        {\"role\": \"user\", \"content\": \"This late pivot means we don't have time to boil the ocean for the client deliverable.\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d83c1cb",
   "metadata": {},
   "source": [
    "# Formatted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc5d104c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.26 ms, sys: 2.05 ms, total: 11.3 ms\n",
      "Wall time: 4.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "userInput = \"blueberry pancakes\"\n",
    "\n",
    "prompt = \"\"\"return a recipe for %s.\n",
    "        Provide your response as a JSON object with the following schema:\n",
    "        {\"dish\": \"%s\", \"ingredients\": [\"\", \"\", ...],\n",
    "        \"instructions\": [\"\", \"\", ... ]}\"\"\" % (userInput, userInput)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "          model = \"gpt-3.5-turbo\",\n",
    "          messages = [\n",
    "            { \"role\": \"system\", \"content\": \"You are a helpful recipe assistant.\"},\n",
    "            { \"role\": \"user\",   \"content\": prompt }\n",
    "          ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7e701cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9733d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = json.loads(json_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d03723fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 cup all-purpose flour',\n",
       " '2 tbsp sugar',\n",
       " '1 tbsp baking powder',\n",
       " '1/2 tsp salt',\n",
       " '1 cup milk',\n",
       " '1 large egg',\n",
       " '2 tbsp melted butter',\n",
       " '1 cup fresh blueberries']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"ingredients\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db048b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In a large mixing bowl, combine the flour, sugar, baking powder, and salt.',\n",
       " 'In a separate bowl, whisk together the milk, egg, and melted butter.',\n",
       " 'Pour the wet ingredients into the dry ingredients and mix until just combined. Be careful not to overmix.',\n",
       " 'Gently fold in the blueberries.',\n",
       " 'Heat a lightly greased skillet or griddle over medium heat.',\n",
       " 'Pour 1/4 cup of batter onto the skillet for each pancake.',\n",
       " 'Cook until bubbles form on the surface of the pancake, then flip and cook for another minute or until golden brown.',\n",
       " 'Repeat with the remaining batter.',\n",
       " 'Serve warm with maple syrup and extra blueberries if desired. Enjoy!']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"instructions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0811b139",
   "metadata": {},
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a0e7e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[{\"role\": \"system\", \"content\": \"You're a professional English-Italian translator.\"}, \n",
    "              {\"role\": \"user\", \"content\": \"Translate 'Be the change that you wish to see in the world.' into Italian\"}],\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca268762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Sii il cambiamento che desideri vedere nel mondo.\"'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc3b0cc",
   "metadata": {},
   "source": [
    "# Process unstructured information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351cfe4a",
   "metadata": {},
   "source": [
    "Inspired by https://platform.openai.com/examples/default-parse-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0d87024",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"There are many fruits that were found on the recently discovered planet Goocrux. \n",
    "There are neoskizzles that grow there, which are purple and taste like candy. There are also \n",
    "loheckles, which are a grayish blue fruit and are very tart, a little bit like a lemon. Pounits \n",
    "are a bright green color and are more savory than sweet. There are also plenty of loopnovas which \n",
    "are a neon pink flavor and taste like cotton candy. Finally, there are fruits called glowls, which \n",
    "have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0354c130",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \n",
    "         \"content\": \"You will be provided with unstructured data, and your task is to parse it into CSV format.\"}, \n",
    "        {\"role\": \"user\", \n",
    "         \"content\": prompt}],\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7529da42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fruit,Color,Flavor\n",
      "neoskizzles,Purple,Candy\n",
      "loheckles,Grayish blue,Tart\n",
      "pounits,Bright green,Savory\n",
      "loopnovas,Neon pink,Cotton candy\n",
      "glowls,Pale orange,Sour and bitter\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0daaad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[{\"role\": \"system\", \"content\": \"\"\"\n",
    "            Read this paragraph \n",
    "            \n",
    "            `%s` \n",
    "            \n",
    "            and use it to answer some questions.\"\"\" % prompt}, \n",
    "              {\"role\": \"user\", \"content\": \"What are pounits?\"}],\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "94e1155b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pounits are bright green fruits found on the planet Goocrux. They are described as more savory than sweet.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec8a68a",
   "metadata": {},
   "source": [
    "<center>\n",
    "     <img src=\"https://raw.githubusercontent.com/DataForScience/Networks/master/data/D4Sci_logo_full.png\" alt=\"Data For Science, Inc\" align=\"center\" border=\"0\" width=300px> \n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
