{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02ce6d4b",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; overflow: hidden;\">\n",
    "    <div style=\"width: 150px; float: left;\"> <img src=\"https://raw.githubusercontent.com/DataForScience/Networks/master/data/D4Sci_logo_ball.png\" alt=\"Data For Science, Inc\" align=\"left\" border=\"0\" width=150px> </div>\n",
    "    <div style=\"float: left; margin-left: 10px;\"> <h1>Generative AI with OpenAI API</h1>\n",
    "<h1>GPT Models</h1>\n",
    "        <p>Bruno Gon√ßalves<br/>\n",
    "        <a href=\"http://www.data4sci.com/\">www.data4sci.com</a><br/>\n",
    "            @bgoncalves, @data4sci</p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1c54b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "import termcolor\n",
    "from termcolor import colored\n",
    "\n",
    "import os\n",
    "import gzip\n",
    "\n",
    "import tqdm as tq\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import watermark\n",
    "\n",
    "%load_ext watermark\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3c67dd",
   "metadata": {},
   "source": [
    "We start by printing out the versions of the libraries we're using for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea24e292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.11.7\n",
      "IPython version      : 8.12.3\n",
      "\n",
      "Compiler    : Clang 14.0.6 \n",
      "OS          : Darwin\n",
      "Release     : 23.5.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 16\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: 2f98fe4b5aabf6921b7e3b8fba71f74cb0ebead8\n",
      "\n",
      "matplotlib: 3.8.0\n",
      "tqdm      : 4.66.4\n",
      "watermark : 2.4.3\n",
      "numpy     : 1.26.4\n",
      "termcolor : 2.4.0\n",
      "openai    : 1.30.5\n",
      "json      : 2.0.9\n",
      "pandas    : 2.1.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -n -v -m -g -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54260c73",
   "metadata": {},
   "source": [
    "Load default figure style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c38e561",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('d4sci.mplstyle')\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7fc648",
   "metadata": {},
   "source": [
    "# Basic Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aede8c61",
   "metadata": {},
   "source": [
    "The first step is generate API key on the OpenAI website and store it as the \"OPENAI_API_KEY\" variable in your local environment. Without it we won't be able to do anything. You can find your API key in your using settings: https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aee0fc",
   "metadata": {},
   "source": [
    "Then we are ready to instantiate the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f2c1ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fbfe94",
   "metadata": {},
   "source": [
    "We start by getting a list of supported models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c58fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = json.loads(client.models.list().json())[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b377a91f",
   "metadata": {},
   "source": [
    "In total we have 32 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "026cce5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f81431",
   "metadata": {},
   "source": [
    "Along with some information about each model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4656071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'dall-e-3',\n",
       "  'created': 1698785189,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'system'},\n",
       " {'id': 'whisper-1',\n",
       "  'created': 1677532384,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'openai-internal'},\n",
       " {'id': 'gpt-4-turbo-2024-04-09',\n",
       "  'created': 1712601677,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'system'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec8e97d",
   "metadata": {},
   "source": [
    "But let's just get a list of model names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "607d946b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "babbage-002\n",
      "dall-e-2\n",
      "dall-e-3\n",
      "davinci-002\n",
      "gpt-3.5-turbo\n",
      "gpt-3.5-turbo-0125\n",
      "gpt-3.5-turbo-0301\n",
      "gpt-3.5-turbo-0613\n",
      "gpt-3.5-turbo-1106\n",
      "gpt-3.5-turbo-16k\n",
      "gpt-3.5-turbo-16k-0613\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-3.5-turbo-instruct-0914\n",
      "gpt-4\n",
      "gpt-4-0125-preview\n",
      "gpt-4-0613\n",
      "gpt-4-1106-preview\n",
      "gpt-4-turbo\n",
      "gpt-4-turbo-2024-04-09\n",
      "gpt-4-turbo-preview\n",
      "gpt-4o\n",
      "gpt-4o-2024-05-13\n",
      "gpt-4o-mini\n",
      "gpt-4o-mini-2024-07-18\n",
      "text-embedding-3-large\n",
      "text-embedding-3-small\n",
      "text-embedding-ada-002\n",
      "tts-1\n",
      "tts-1-1106\n",
      "tts-1-hd\n",
      "tts-1-hd-1106\n",
      "whisper-1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(sorted([model[\"id\"] for model in model_list])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23406594",
   "metadata": {},
   "source": [
    "## Basic Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e584dc4c",
   "metadata": {},
   "source": [
    "The recommended model for exploration is `gpt-3.5-turbo`, so we'll stick with it for now. The basic setup is relatively straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25584bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"What was Superman's weakness?\"\n",
    "        },\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71ce20f",
   "metadata": {},
   "source": [
    "Which produces a response object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d50520ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.chat.chat_completion.ChatCompletion"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a84d87",
   "metadata": {},
   "source": [
    "Which we can treat as a named tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a319f9",
   "metadata": {},
   "source": [
    "The model answer can be found in the \"message\" dictionary inside the \"choices\" list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4740c693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Superman's weakness is Kryptonite, a radioactive mineral from his home planet of Krypton. Exposure to Kryptonite weakens Superman and can potentially kill him.\", role='assistant', function_call=None, tool_calls=None))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d17821e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Superman's weakness is Kryptonite, a mineral from his home planet of Krypton that can weaken and harm him. Additionally, exposure to red solar radiation can also weaken him.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d4c18e",
   "metadata": {},
   "source": [
    "To request multiple answers, we must include the `n` parameter with the number of answers we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b014c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.2 ms, sys: 2.28 ms, total: 13.5 ms\n",
      "Wall time: 4.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What are the different kinds of Kryptonite?\"},\n",
    "    ],\n",
    "    n=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202531fc",
   "metadata": {},
   "source": [
    "And we can access each of the answers individually int he choices list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe218bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Assistant\n",
      "==========\n",
      "There are numerous variations of Kryptonite in the DC Comics universe, each with different effects on Kryptonians, particularly Superman. Some of the most well-known types of Kryptonite include:\n",
      "\n",
      "1. Green Kryptonite: This is the most common form of Kryptonite and has the ability to weaken and harm Kryptonians, especially Superman. Exposure to green Kryptonite can leave them vulnerable, powerless, or even fatally poisoned.\n",
      "\n",
      "2. Red Kryptonite: This type of Kryptonite has unpredictable effects on Kryptonians, often altering their behavior or physical appearance temporarily. It can also cause psychological changes, making the individual act out of character.\n",
      "\n",
      "3. Blue Kryptonite: Blue Kryptonite is typically harmless to Kryptonians, but it has been known to have negative effects on Bizarro, a flawed duplicate of Superman.\n",
      "\n",
      "4. Gold Kryptonite: Gold Kryptonite has the ability to permanently strip a Kryptonian of their powers, rendering them powerless for the rest of their lives.\n",
      "\n",
      "5. White Kryptonite: White Kryptonite is lethal to plant life, causing any plant-based organism to wither and die upon exposure.\n",
      "\n",
      "6. Black Kryptonite: Black Kryptonite has the ability to split a Kryptonian into two separate beings, usually a good and an evil version of themselves.\n",
      "\n",
      "These are just a few examples of the different types of Kryptonite that exist in the DC Comics universe. Each variation has unique properties and effects on Kryptonians, making them a formidable weapon against Superman and other characters from the planet Krypton.\n",
      "==========\n",
      "\n",
      "==========\n",
      "Assistant\n",
      "==========\n",
      "There are several different kinds of Kryptonite, each with its own unique properties and effects on Kryptonians (such as Superman):\n",
      "\n",
      "1. Green Kryptonite: The most well-known and common form of Kryptonite, green Kryptonite is deadly to Kryptonians and weakens them, causing them to lose their powers and become vulnerable to physical harm.\n",
      "\n",
      "2. Red Kryptonite: Red Kryptonite has unpredictable effects on Kryptonians, causing temporary or permanent changes in their behavior, abilities, and physiology. Each exposure to red Kryptonite has a different effect, making it a highly dangerous substance.\n",
      "\n",
      "3. Blue Kryptonite: Blue Kryptonite has the opposite effect of green Kryptonite, boosting a Kryptonian's powers and strengthening them. It is often used as a remedy for the effects of green Kryptonite exposure.\n",
      "\n",
      "4. Gold Kryptonite: Gold Kryptonite permanently removes a Kryptonian's powers, making them effectively human. It is one of the most dangerous forms of Kryptonite for Kryptonians.\n",
      "\n",
      "5. White Kryptonite: White Kryptonite is deadly to plant life and other forms of vegetation, but has no effect on Kryptonians.\n",
      "\n",
      "6. Black Kryptonite: Black Kryptonite has the ability to split a Kryptonian into two separate beings, representing their good and evil sides. It is a powerful and dangerous substance with significant consequences for those exposed to it.\n",
      "==========\n",
      "\n",
      "==========\n",
      "Assistant\n",
      "==========\n",
      "There are several different types of Kryptonite in the DC Comics universe, each with different effects on the character Superman and other Kryptonians:\n",
      "\n",
      "1. Green Kryptonite: The most common type of Kryptonite, green Kryptonite is deadly to Kryptonians, weakening them and eventually killing them if exposed for too long.\n",
      "\n",
      "2. Red Kryptonite: Red Kryptonite causes unpredictable and temporary changes in Kryptonians, altering their personalities or physical abilities in various ways.\n",
      "\n",
      "3. Blue Kryptonite: Blue Kryptonite is harmless to Kryptonians, but has negative effects on other Kryptonian beings, such as Bizarro.\n",
      "\n",
      "4. Gold Kryptonite: Gold Kryptonite permanently removes a Kryptonian's powers, rendering them completely human.\n",
      "\n",
      "5. Black Kryptonite: Black Kryptonite can split a Kryptonian into two separate beings, usually representing their good and evil sides.\n",
      "\n",
      "6. White Kryptonite: White Kryptonite is deadly to plant life, but has no effect on Kryptonians.\n",
      "\n",
      "7. X-Kryptonite: X-Kryptonite can give humans temporary superpowers similar to those of Kryptonians.\n",
      "==========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for output in response.choices:\n",
    "    print(\"==========\")\n",
    "    print(output.message.role.title()) \n",
    "    print(\"==========\")\n",
    "    print(output.message.content)\n",
    "    print(\"==========\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b807f9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=859, prompt_tokens=17, total_tokens=876)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c1fcb2",
   "metadata": {},
   "source": [
    "# Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "973c3af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.35 ms, sys: 1.93 ms, total: 11.3 ms\n",
      "Wall time: 667 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a dad joke\"},\n",
    "    ],\n",
    "    temperature=1.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b20abae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why was the math book sad?\n",
      "\n",
      "Because it had too many problems.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4147901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.3 ms, sys: 3.11 ms, total: 15.4 ms\n",
      "Wall time: 773 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a dad joke\"},\n",
    "    ],\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0523be32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why couldn't the bicycle stand up by itself?\n",
      "\n",
      "Because it was two tired!\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc425a6d",
   "metadata": {},
   "source": [
    "# Function Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e9ac278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(messages, functions):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        # Define the functions the model is allowed to use\n",
    "        functions=functions\n",
    "    )\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a8bd067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_conversation(messages):\n",
    "    role_to_color = {\n",
    "        \"system\": \"red\",\n",
    "        \"user\": \"green\",\n",
    "        \"assistant\": \"blue\",\n",
    "        \"function\": \"magenta\",\n",
    "    }\n",
    "    \n",
    "    for message in messages:\n",
    "#         print(message)\n",
    "        if message[\"role\"] == \"system\":\n",
    "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message['role']]))\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message['role']]))\n",
    "        elif message[\"role\"] == \"assistant\" and message['function_call']:\n",
    "            print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color[message['role']]))\n",
    "        elif message[\"role\"] == \"assistant\" and not message['function_call']:\n",
    "            print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message['role']]))\n",
    "        elif message[\"role\"] == \"function\":\n",
    "            print(colored(f\"function ({message.name}): {message.content}\\n\", role_to_color[message.role]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ac831b",
   "metadata": {},
   "source": [
    "Let's create some function specifications to interface with a hypothetical weather API. We'll pass these function specification to the Chat Completions API in order to generate function arguments that adhere to the specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ee74719",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"format\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"location\", \"format\"],\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248f9dae",
   "metadata": {},
   "source": [
    "If we prompt the model about the current weather, it will respond with some clarifying questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8839c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "messages.append(\n",
    "    {\"role\": \"system\", \n",
    "     \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"\n",
    "    })\n",
    "\n",
    "messages.append(\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": \"What's the weather like today\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "791d9227",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_response = chat(messages, functions=functions)\n",
    "\n",
    "assistant_message = chat_response.choices[0].message\n",
    "\n",
    "messages.append({\n",
    " \"role\":  assistant_message.role,\n",
    " \"content\":  assistant_message.content,\n",
    " \"function_call\":  assistant_message.function_call,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c8f56b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msystem: Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\n",
      "\u001b[0m\n",
      "\u001b[32muser: What's the weather like today\n",
      "\u001b[0m\n",
      "\u001b[34massistant: Sure, can you please provide me with the location for which you want to know the weather?\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pretty_print_conversation(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6928e1",
   "metadata": {},
   "source": [
    "Once we provide the missing information, it will generate the appropriate function arguments for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74aaf121",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": \"I'm in New York, NY.\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8f72364",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_response = chat(messages, functions=functions)\n",
    "\n",
    "assistant_message = chat_response.choices[0].message\n",
    "\n",
    "messages.append({\n",
    " \"role\":  assistant_message.role,\n",
    " \"content\":  assistant_message.content,\n",
    " \"function_call\":  assistant_message.function_call,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc125814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msystem: Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\n",
      "\u001b[0m\n",
      "\u001b[32muser: What's the weather like today\n",
      "\u001b[0m\n",
      "\u001b[34massistant: Sure, can you please provide me with the location for which you want to know the weather?\n",
      "\u001b[0m\n",
      "\u001b[32muser: I'm in New York, NY.\n",
      "\u001b[0m\n",
      "\u001b[34massistant: FunctionCall(arguments='{\"location\":\"New York, NY\",\"format\":\"celsius\"}', name='get_current_weather')\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pretty_print_conversation(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d35115e",
   "metadata": {},
   "source": [
    "## Few-shot prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a10943",
   "metadata": {},
   "source": [
    "We can also provide several examples of mappings between input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f30283de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This last-minute change means we can't spend excessive time on the client's project.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful, pattern-following assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Help me translate the following corporate jargon into plain English.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Sure, I'd be happy to!\"},\n",
    "        {\"role\": \"user\", \"content\": \"New synergies will help drive top-line growth.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Things working well together will increase revenue.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Let's circle back when we have more bandwidth to touch base on opportunities for increased leverage.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Let's talk later when we're less busy about how to do better.\"},\n",
    "        {\"role\": \"user\", \"content\": \"This late pivot means we don't have time to boil the ocean for the client deliverable.\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b13d8e",
   "metadata": {},
   "source": [
    "# Formatted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c06a8fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.8 ms, sys: 1.86 ms, total: 12.7 ms\n",
      "Wall time: 3.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "userInput = \"blueberry pancakes\"\n",
    "\n",
    "prompt = \"\"\"return a recipe for %s.\n",
    "        Provide your response as a JSON object with the following schema:\n",
    "        {\"dish\": \"%s\", \"ingredients\": [\"\", \"\", ...],\n",
    "        \"instructions\": [\"\", \"\", ... ]}\"\"\" % (userInput, userInput)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "          model = \"gpt-3.5-turbo\",\n",
    "          messages = [\n",
    "            { \"role\": \"system\", \"content\": \"You are a helpful recipe assistant.\"},\n",
    "            { \"role\": \"user\",   \"content\": prompt }\n",
    "          ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bcc7a9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71070f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = json.loads(json_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3aa0cd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dish': 'blueberry pancakes',\n",
      " 'ingredients': ['1 cup all-purpose flour',\n",
      "                 '2 tbsp sugar',\n",
      "                 '1 tbsp baking powder',\n",
      "                 '1/2 tsp salt',\n",
      "                 '1 cup milk',\n",
      "                 '1 large egg',\n",
      "                 '2 tbsp unsalted butter, melted',\n",
      "                 '1 cup fresh blueberries',\n",
      "                 'Butter or oil for cooking'],\n",
      " 'instructions': ['In a bowl, whisk together the flour, sugar, baking powder, '\n",
      "                  'and salt.',\n",
      "                  'In another bowl, mix the milk, egg, and melted butter.',\n",
      "                  'Combine the wet and dry ingredients, then gently fold in '\n",
      "                  'the blueberries.',\n",
      "                  'Heat a skillet or griddle over medium heat and grease with '\n",
      "                  'butter or oil.',\n",
      "                  'Pour 1/4 cup of batter onto the skillet for each pancake.',\n",
      "                  'Cook until bubbles form on the surface, then flip and cook '\n",
      "                  'until golden brown.',\n",
      "                  'Repeat with the remaining batter.',\n",
      "                  'Serve the blueberry pancakes warm with maple syrup and '\n",
      "                  'extra blueberries.']}\n"
     ]
    }
   ],
   "source": [
    "pprint(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acee6bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 cup all-purpose flour',\n",
       " '2 tbsp sugar',\n",
       " '1 tbsp baking powder',\n",
       " '1/2 tsp salt',\n",
       " '1 cup milk',\n",
       " '1 large egg',\n",
       " '2 tbsp unsalted butter, melted',\n",
       " '1 cup fresh blueberries',\n",
       " 'Butter or oil for cooking']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"ingredients\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "574e7e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In a bowl, whisk together the flour, sugar, baking powder, and salt.',\n",
       " 'In another bowl, mix the milk, egg, and melted butter.',\n",
       " 'Combine the wet and dry ingredients, then gently fold in the blueberries.',\n",
       " 'Heat a skillet or griddle over medium heat and grease with butter or oil.',\n",
       " 'Pour 1/4 cup of batter onto the skillet for each pancake.',\n",
       " 'Cook until bubbles form on the surface, then flip and cook until golden brown.',\n",
       " 'Repeat with the remaining batter.',\n",
       " 'Serve the blueberry pancakes warm with maple syrup and extra blueberries.']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"instructions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3ff2eb",
   "metadata": {},
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99e3840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[{\"role\": \"system\", \"content\": \"You're a professional English-Italian translator.\"}, \n",
    "              {\"role\": \"user\", \"content\": \"Translate 'Be the change that you wish to see in the world.' into Italian\"}],\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c8c0eadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Sii il cambiamento che desideri vedere nel mondo.\"'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0837bd30",
   "metadata": {},
   "source": [
    "# Process unstructured information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f31a36",
   "metadata": {},
   "source": [
    "Inspired by https://platform.openai.com/examples/default-parse-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8330f0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"There are many fruits that were found on the recently discovered planet Goocrux. \n",
    "There are neoskizzles that grow there, which are purple and taste like candy. There are also \n",
    "loheckles, which are a grayish blue fruit and are very tart, a little bit like a lemon. Pounits \n",
    "are a bright green color and are more savory than sweet. There are also plenty of loopnovas which \n",
    "are a neon pink flavor and taste like cotton candy. Finally, there are fruits called glowls, which \n",
    "have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f64315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \n",
    "         \"content\": \"You will be provided with unstructured data, and your task is to parse it into CSV format.\"}, \n",
    "        {\"role\": \"user\", \n",
    "         \"content\": prompt}],\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd609dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fruit,Color,Flavor\n",
      "neoskizzles,purple,candy\n",
      "loheckles,grayish blue,tart\n",
      "pounits,bright green,savory\n",
      "loopnovas,neon pink,cotton candy\n",
      "glowls,pale orange,sour and bitter\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7fb3753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[{\"role\": \"system\", \"content\": \"\"\"\n",
    "            Read this paragraph \n",
    "            \n",
    "            `%s` \n",
    "            \n",
    "            and use it to answer some questions.\"\"\" % prompt}, \n",
    "              {\"role\": \"user\", \"content\": \"What are pounits?\"}],\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "80046491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pounits are bright green fruits that are more savory than sweet.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8179e763",
   "metadata": {},
   "source": [
    "<center>\n",
    "     <img src=\"https://raw.githubusercontent.com/DataForScience/Networks/master/data/D4Sci_logo_full.png\" alt=\"Data For Science, Inc\" align=\"center\" border=\"0\" width=300px> \n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
