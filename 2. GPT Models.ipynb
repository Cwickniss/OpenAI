{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2f6395c",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; overflow: hidden;\">\n",
    "    <div style=\"width: 150px; float: left;\"> <img src=\"https://raw.githubusercontent.com/DataForScience/Networks/master/data/D4Sci_logo_ball.png\" alt=\"Data For Science, Inc\" align=\"left\" border=\"0\" width=150px> </div>\n",
    "    <div style=\"float: left; margin-left: 10px;\"> <h1>Generative AI with OpenAI API</h1>\n",
    "<h1>GPT Models</h1>\n",
    "        <p>Bruno Gon√ßalves<br/>\n",
    "        <a href=\"http://www.data4sci.com/\">www.data4sci.com</a><br/>\n",
    "            @bgoncalves, @data4sci</p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f57712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "import termcolor\n",
    "from termcolor import colored\n",
    "\n",
    "import os\n",
    "import gzip\n",
    "\n",
    "import tqdm as tq\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import watermark\n",
    "\n",
    "%load_ext watermark\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b834f9a",
   "metadata": {},
   "source": [
    "We start by printing out the versions of the libraries we're using for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "876a1b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.11.7\n",
      "IPython version      : 8.12.3\n",
      "\n",
      "Compiler    : Clang 14.0.6 \n",
      "OS          : Darwin\n",
      "Release     : 23.4.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 16\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: 5217868ae783ab0315a9d79f2e1ac0fb25095003\n",
      "\n",
      "watermark : 2.4.3\n",
      "pandas    : 2.1.4\n",
      "termcolor : 2.4.0\n",
      "tqdm      : 4.66.2\n",
      "numpy     : 1.26.4\n",
      "matplotlib: 3.8.0\n",
      "json      : 2.0.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -n -v -m -g -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfbc9e5",
   "metadata": {},
   "source": [
    "Load default figure style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d7f3a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('d4sci.mplstyle')\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a32f69a",
   "metadata": {},
   "source": [
    "# Basic Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c9d274",
   "metadata": {},
   "source": [
    "The first step is generate API key on the OpenAI website and store it as the \"OPENAI_API_KEY\" variable in your local environment. Without it we won't be able to do anything. You can find your API key in your using settings: https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc1b830-97e3-443a-811c-ddd20d2ecbb9",
   "metadata": {},
   "source": [
    "Then we are ready to instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5f43171-b255-4219-a5dc-cc4535a47e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60dc01d",
   "metadata": {},
   "source": [
    "We start by getting a list of supported models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e7643bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = json.loads(client.models.list().json())[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e14e3d",
   "metadata": {},
   "source": [
    "In total we have 32 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96f6b9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e11616",
   "metadata": {},
   "source": [
    "Along with some information about each model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "102a537d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'dall-e-3',\n",
       "  'created': 1698785189,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'system'},\n",
       " {'id': 'gpt-4-1106-preview',\n",
       "  'created': 1698957206,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'system'},\n",
       " {'id': 'whisper-1',\n",
       "  'created': 1677532384,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'openai-internal'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f448b4",
   "metadata": {},
   "source": [
    "But let's just get a list of model names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42962461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "babbage-002\n",
      "dall-e-2\n",
      "dall-e-3\n",
      "davinci-002\n",
      "gpt-3.5-turbo\n",
      "gpt-3.5-turbo-0125\n",
      "gpt-3.5-turbo-0301\n",
      "gpt-3.5-turbo-0613\n",
      "gpt-3.5-turbo-1106\n",
      "gpt-3.5-turbo-16k\n",
      "gpt-3.5-turbo-16k-0613\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-3.5-turbo-instruct-0914\n",
      "gpt-4\n",
      "gpt-4-0125-preview\n",
      "gpt-4-0613\n",
      "gpt-4-1106-preview\n",
      "gpt-4-1106-vision-preview\n",
      "gpt-4-turbo\n",
      "gpt-4-turbo-2024-04-09\n",
      "gpt-4-turbo-preview\n",
      "gpt-4-vision-preview\n",
      "gpt-4o\n",
      "gpt-4o-2024-05-13\n",
      "gpt-4o-test-shared\n",
      "text-embedding-3-large\n",
      "text-embedding-3-small\n",
      "text-embedding-ada-002\n",
      "tts-1\n",
      "tts-1-1106\n",
      "tts-1-hd\n",
      "tts-1-hd-1106\n",
      "whisper-1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(sorted([model[\"id\"] for model in model_list])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4770f275",
   "metadata": {},
   "source": [
    "## Basic Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ce70f1",
   "metadata": {},
   "source": [
    "The recommended model for exploration is `gpt-3.5-turbo`, so we'll stick with it for now. The basic setup is relatively straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adafc6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"What was Superman's weakness?\"\n",
    "        },\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa3d11a",
   "metadata": {},
   "source": [
    "Which produces a response object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44cbe6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.chat.chat_completion.ChatCompletion"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222b82bc",
   "metadata": {},
   "source": [
    "Which we can treat as a named tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad0fb2d",
   "metadata": {},
   "source": [
    "The model answer can be found in the \"message\" dictionary inside the \"choices\" list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "832a11d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Superman's weakness is kryptonite, a radioactive mineral from his home planet of Krypton. Exposure to kryptonite weakens and can ultimately kill Superman.\", role='assistant', function_call=None, tool_calls=None))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f96500",
   "metadata": {},
   "source": [
    "To request multiple answers, we must include the `n` parameter with the number of answers we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "934d4574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.77 ms, sys: 1.1 ms, total: 4.87 ms\n",
      "Wall time: 5.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What are the different kinds of Kryptonite?\"},\n",
    "    ],\n",
    "    n=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c985ec",
   "metadata": {},
   "source": [
    "And we can access each of the answers individually int he choices list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bcad922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Assistant\n",
      "==========\n",
      "There are several different kinds of Kryptonite, each with different effects on the character Superman. Some of the most well-known types of Kryptonite include:\n",
      "\n",
      "1. Green Kryptonite: The most common form of Kryptonite, green Kryptonite emits radiation that weakens Superman and can ultimately kill him if he is exposed to it for too long.\n",
      "\n",
      "2. Red Kryptonite: Red Kryptonite has unpredictable effects on Superman, often causing temporary changes in his behavior or powers. These effects are usually temporary and wear off after a certain amount of time.\n",
      "\n",
      "3. Gold Kryptonite: Gold Kryptonite permanently removes Superman's powers and abilities when he is exposed to it. However, it does not have any harmful effects on him like green Kryptonite does.\n",
      "\n",
      "4. Blue Kryptonite: Blue Kryptonite affects Bizarro, a flawed clone of Superman, in the same way that green Kryptonite affects Superman. It weakens Bizarro and can cause harm to him.\n",
      "\n",
      "5. White Kryptonite: White Kryptonite affects plant life, causing rapid growth and mutation in plants while simultaneously killing any plant-based life forms.\n",
      "\n",
      "6. Black Kryptonite: Black Kryptonite can split an individual into two separate beings, each representing a different side of their personality or morality.\n",
      "\n",
      "These are just a few examples of the different types of Kryptonite that exist in the DC comics universe, each with its own unique effects on Superman and other characters.\n",
      "==========\n",
      "\n",
      "==========\n",
      "Assistant\n",
      "==========\n",
      "There are several different types of Kryptonite, each with its own unique properties and effects on Superman and other Kryptonians:\n",
      "\n",
      "1. Green Kryptonite: This is the most common and well-known form of Kryptonite. It is highly radioactive to Kryptonians and weakens them, causing nausea, weakness, and potential death if exposed for extended periods of time.\n",
      "\n",
      "2. Red Kryptonite: This form of Kryptonite has unpredictable effects on Kryptonians, causing temporary changes in their behavior, powers, or physical appearance.\n",
      "\n",
      "3. Blue Kryptonite: This form of Kryptonite affects Bizarro, a flawed duplicate of Superman, by weakening him.\n",
      "\n",
      "4. Gold Kryptonite: This form of Kryptonite permanently removes a Kryptonian's powers when exposed to it.\n",
      "\n",
      "5. White Kryptonite: This form of Kryptonite is deadly to plant life and can be used as a weapon against plant-based foes.\n",
      "\n",
      "6. Black Kryptonite: This form of Kryptonite can split a Kryptonian into two separate beings, often representing their good and evil sides.\n",
      "\n",
      "7. X-Kryptonite: This synthetic form of Kryptonite grants humans temporary superpowers but can also have unpredictable side effects.\n",
      "\n",
      "8. Pink Kryptonite: This form of Kryptonite affects Superman in a way that suggests he is gay, causing him to exhibit stereotypical traits associated with homosexuality.\n",
      "\n",
      "9. Orange Kryptonite: This form of Kryptonite makes Kryptonians lose their rational thought and become extremely aggressive.\n",
      "\n",
      "These are just a few examples of the different types of Kryptonite that have been introduced in various comic book storylines over the years.\n",
      "==========\n",
      "\n",
      "==========\n",
      "Assistant\n",
      "==========\n",
      "1. Green Kryptonite - The most commonly known form of Kryptonite, green Kryptonite is highly toxic to Kryptonians (including Superman) and weakens them when they are exposed to it.\n",
      "\n",
      "2. Red Kryptonite - Red Kryptonite has unpredictable effects on Kryptonians, causing them to undergo temporary changes in behavior or abilities.\n",
      "\n",
      "3. Blue Kryptonite - Blue Kryptonite has been shown to have a calming effect on Kryptonians, reducing their aggression and making them more vulnerable.\n",
      "\n",
      "4. Gold Kryptonite - Gold Kryptonite permanently removes a Kryptonian's powers, rendering them powerless.\n",
      "\n",
      "5. Black Kryptonite - Black Kryptonite can split a Kryptonian into two separate beings, one good and one evil.\n",
      "\n",
      "6. White Kryptonite - White Kryptonite is lethal to plant life, including alien plant life from Krypton.\n",
      "\n",
      "7. Silver Kryptonite - Silver Kryptonite induces extreme paranoia in Kryptonians, causing them to hallucinate and become delusional.\n",
      "==========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for output in response.choices:\n",
    "    print(\"==========\")\n",
    "    print(output.message.role.title()) \n",
    "    print(\"==========\")\n",
    "    print(output.message.content)\n",
    "    print(\"==========\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "279d48c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=856, prompt_tokens=17, total_tokens=873)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18509d4",
   "metadata": {},
   "source": [
    "# Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ddb64d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.6 ms, sys: 2.28 ms, total: 7.88 ms\n",
      "Wall time: 5.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a short story\"},\n",
    "    ],\n",
    "    temperature=1.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22fd09b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a young girl named Lily who lived in a small village at the edge of a deep, dark forest. Every day, she would roam the woods and explore all its hidden treasures, feeling completely at peace within the trees and the soft whispers of the wind.\n",
      "\n",
      "But one day, a wicked witch cast a spell on the forest, causing darkness to descend upon it and filling it with evil creatures. The villagers were terrified and pleaded for someone to save them from the curse that had befallen their beloved home.\n",
      "\n",
      "Lily, realizing the danger that had befallen the forest she adored so much, volunteered to confront the witch and end her wicked ways. Armed with nothing but her courage and determination, Lily set out on a perilous journey to the witch's castle.\n",
      "\n",
      "Along the way, Lily encountered all kinds of fearsome beasts and traps set by the witch to deter her from reaching her goal. But with each challenge, Lily grew stronger and more fearless, drawing upon the love she felt for her forest as a source of inner strength.\n",
      "\n",
      "Finally, she reached the castle and confronted the witch in a fierce battle of magical powers. With one final burst of energy, Lily overcame the witch, breaking the curse she had cast over the forest and restoring light and safety to the land.\n",
      "\n",
      "The villagers rejoiced as Lily emerged victorious, hailed as a hero for her bravery and sacrifice. From that day on, she was known as the Forest Guardian, revered by all for her selfless act of saving their home.\n",
      "\n",
      "And so, peace and harmony were restored to the once-darkened woods, and Lily's love and courage shone bright for all to see.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86beb86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.37 ms, sys: 1.95 ms, total: 7.32 ms\n",
      "Wall time: 4.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a short story\"},\n",
    "    ],\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1855d3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a small village nestled in the mountains, there lived a young girl named Lily. She was known for her kindness and generosity, always willing to help those in need.\n",
      "\n",
      "One day, a terrible storm hit the village, causing widespread damage and leaving many families homeless. Lily knew she had to do something to help. She gathered her friends and together they started a relief effort, collecting food, clothing, and supplies for those affected by the storm.\n",
      "\n",
      "As they worked tirelessly to distribute the donations, word of their efforts spread throughout the village. Soon, more and more people joined in, offering their support and assistance. The village came together in a way it never had before, united in their mission to help their neighbors in need.\n",
      "\n",
      "Thanks to Lily's leadership and the community's collective efforts, the village was able to rebuild and recover from the storm in record time. The experience brought the villagers closer together and taught them the power of compassion and unity.\n",
      "\n",
      "From that day on, Lily was known as a hero in the village, a shining example of the difference one person can make when they choose to act with kindness and generosity. And the village thrived, stronger and more united than ever before.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff6e2bc",
   "metadata": {},
   "source": [
    "# Function Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ec02e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(messages, functions):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        # Define the functions the model is allowed to use\n",
    "        functions=functions\n",
    "    )\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85bfb94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_conversation(messages):\n",
    "    role_to_color = {\n",
    "        \"system\": \"red\",\n",
    "        \"user\": \"green\",\n",
    "        \"assistant\": \"blue\",\n",
    "        \"function\": \"magenta\",\n",
    "    }\n",
    "    \n",
    "    for message in messages:\n",
    "        print(message)\n",
    "        if message[\"role\"] == \"system\":\n",
    "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message['role']]))\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message['role']]))\n",
    "        elif message[\"role\"] == \"assistant\" and message['function_call']:\n",
    "            print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color[message['role']]))\n",
    "        elif message[\"role\"] == \"assistant\" and not message['function_call']:\n",
    "            print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message['role']]))\n",
    "        elif message[\"role\"] == \"function\":\n",
    "            print(colored(f\"function ({message.name}): {message.content}\\n\", role_to_color[message.role]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44263a09",
   "metadata": {},
   "source": [
    "Let's create some function specifications to interface with a hypothetical weather API. We'll pass these function specification to the Chat Completions API in order to generate function arguments that adhere to the specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d50ae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"format\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"location\", \"format\"],\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fe13f7",
   "metadata": {},
   "source": [
    "If we prompt the model about the current weather, it will respond with some clarifying questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dea82333",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "messages.append(\n",
    "    {\"role\": \"system\", \n",
    "     \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"\n",
    "    })\n",
    "\n",
    "messages.append(\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": \"What's the weather like today\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa5dfb9",
   "metadata": {},
   "source": [
    "Once we provide the missing information, it will generate the appropriate function arguments for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82527ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": \"I'm in New York, NY.\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82f112a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_response = chat(messages, functions=functions)\n",
    "assistant_message = chat_response.choices[0].message\n",
    "messages.append({\n",
    " \"role\":  assistant_message.role,\n",
    " \"content\":  assistant_message.content,\n",
    " \"function_call\":  assistant_message.function_call,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85060c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'system', 'content': \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"}\n",
      "\u001b[31msystem: Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\n",
      "\u001b[0m\n",
      "{'role': 'user', 'content': \"What's the weather like today\"}\n",
      "\u001b[32muser: What's the weather like today\n",
      "\u001b[0m\n",
      "{'role': 'user', 'content': \"I'm in New York, NY.\"}\n",
      "\u001b[32muser: I'm in New York, NY.\n",
      "\u001b[0m\n",
      "{'role': 'assistant', 'content': None, 'function_call': FunctionCall(arguments='{\"location\":\"New York, NY\",\"format\":\"celsius\"}', name='get_current_weather')}\n",
      "\u001b[34massistant: FunctionCall(arguments='{\"location\":\"New York, NY\",\"format\":\"celsius\"}', name='get_current_weather')\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pretty_print_conversation(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8a12a1",
   "metadata": {},
   "source": [
    "## Few-shot prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bca0dde",
   "metadata": {},
   "source": [
    "We can also provide several examples of mappings between input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80a730c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This sudden change in direction means we don't have time to do everything for the client.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful, pattern-following assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Help me translate the following corporate jargon into plain English.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Sure, I'd be happy to!\"},\n",
    "        {\"role\": \"user\", \"content\": \"New synergies will help drive top-line growth.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Things working well together will increase revenue.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Let's circle back when we have more bandwidth to touch base on opportunities for increased leverage.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Let's talk later when we're less busy about how to do better.\"},\n",
    "        {\"role\": \"user\", \"content\": \"This late pivot means we don't have time to boil the ocean for the client deliverable.\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d83c1cb",
   "metadata": {},
   "source": [
    "# Formatted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc5d104c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.92 ms, sys: 1.01 ms, total: 6.93 ms\n",
      "Wall time: 5.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "userInput = \"blueberry pancakes\"\n",
    "\n",
    "prompt = \"\"\"return a recipe for %s.\n",
    "        Provide your response as a JSON object with the following schema:\n",
    "        {\"dish\": \"%s\", \"ingredients\": [\"\", \"\", ...],\n",
    "        \"instructions\": [\"\", \"\", ... ]}\"\"\" % (userInput, userInput)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "          model = \"gpt-3.5-turbo\",\n",
    "          messages = [\n",
    "            { \"role\": \"system\", \"content\": \"You are a helpful recipe assistant.\"},\n",
    "            { \"role\": \"user\",   \"content\": prompt }\n",
    "          ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7e701cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9733d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = json.loads(json_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d03723fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 cup all-purpose flour',\n",
       " '2 tablespoons granulated sugar',\n",
       " '2 teaspoons baking powder',\n",
       " '1/2 teaspoon salt',\n",
       " '1 cup milk',\n",
       " '1 large egg',\n",
       " '2 tablespoons unsalted butter, melted',\n",
       " '1 cup fresh blueberries',\n",
       " 'Butter or oil for cooking']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"ingredients\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db048b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In a large bowl, whisk together the flour, sugar, baking powder, and salt.',\n",
       " 'In a separate bowl, whisk together the milk, egg, and melted butter.',\n",
       " 'Pour the wet ingredients into the dry ingredients and stir until just combined.',\n",
       " 'Gently fold in the blueberries.',\n",
       " 'Heat a skillet or griddle over medium heat and grease with butter or oil.',\n",
       " 'Pour 1/4 cup of batter onto the skillet for each pancake.',\n",
       " 'Cook for 2-3 minutes until bubbles form on the surface, then flip and cook for another 2 minutes or until golden brown.',\n",
       " 'Repeat with the remaining batter.',\n",
       " 'Serve the blueberry pancakes warm with maple syrup and extra blueberries on top. Enjoy!']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"instructions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0811b139",
   "metadata": {},
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a0e7e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[{\"role\": \"system\", \"content\": \"You're a professional English-Italian translator.\"}, \n",
    "              {\"role\": \"user\", \"content\": \"Translate 'Be the change that you wish to see in the world.' into Italian\"}],\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca268762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Sii il cambiamento che desideri vedere nel mondo.\"'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc3b0cc",
   "metadata": {},
   "source": [
    "# Process unstructured information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351cfe4a",
   "metadata": {},
   "source": [
    "Inspired by https://platform.openai.com/examples/default-parse-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0d87024",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"There are many fruits that were found on the recently discovered planet Goocrux. \n",
    "There are neoskizzles that grow there, which are purple and taste like candy. There are also \n",
    "loheckles, which are a grayish blue fruit and are very tart, a little bit like a lemon. Pounits \n",
    "are a bright green color and are more savory than sweet. There are also plenty of loopnovas which \n",
    "are a neon pink flavor and taste like cotton candy. Finally, there are fruits called glowls, which \n",
    "have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0354c130",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \n",
    "         \"content\": \"You will be provided with unstructured data, and your task is to parse it into CSV format.\"}, \n",
    "        {\"role\": \"user\", \n",
    "         \"content\": prompt}],\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7529da42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fruit,Color,Flavor\n",
      "neoskizzles,purple,candy\n",
      "loheckles,grayish blue,tart\n",
      "pounits,bright green,savory\n",
      "loopnovas,neon pink,cotton candy\n",
      "glowls,pale orange,sour and bitter\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0daaad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[{\"role\": \"system\", \"content\": \"\"\"\n",
    "            Read this paragraph \n",
    "            \n",
    "            `%s` \n",
    "            \n",
    "            and use it to answer some questions.\"\"\" % prompt}, \n",
    "              {\"role\": \"user\", \"content\": \"What are pounits?\"}],\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94e1155b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pounits are bright green fruits found on the planet Goocrux. They are described as more savory than sweet.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec8a68a",
   "metadata": {},
   "source": [
    "<center>\n",
    "     <img src=\"https://raw.githubusercontent.com/DataForScience/Networks/master/data/D4Sci_logo_full.png\" alt=\"Data For Science, Inc\" align=\"center\" border=\"0\" width=300px> \n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
